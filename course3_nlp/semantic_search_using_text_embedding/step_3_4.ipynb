{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf9d6626",
   "metadata": {},
   "source": [
    "EXPLANATION: https://www.youtube.com/watch?v=fmN19jXkH5o&t=1s\n",
    "\n",
    "# Steps 3 & 4: Querying a Completion Model with a Custom Text Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0478d18",
   "metadata": {},
   "source": [
    "Add your API key to the cell below then run it."
   ]
  },
  {
   "cell_type": "code",
   "id": "186b2c28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T21:07:11.888788Z",
     "start_time": "2025-01-26T21:07:10.403109Z"
    }
   },
   "source": [
    "import openai\n",
    "openai.api_base = \"https://openai.vocareum.com/v1\"\n",
    "openai.api_key = \"CRAP\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "8fa50906",
   "metadata": {},
   "source": [
    "The code below loads in the data sorted by cosine distance that you previously created. Run it as-is."
   ]
  },
  {
   "cell_type": "code",
   "id": "3fd3a3ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T21:07:14.724086Z",
     "start_time": "2025-01-26T21:07:11.904463Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"distances.csv\", index_col=0)\n",
    "df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                                 text  \\\n",
       "2   There was widespread damage in an area of abou...   \n",
       "45  The USGS Prompt Assessment of Global Earthquak...   \n",
       "46  The United Nations Development Programme estim...   \n",
       "0   On 6 February 2023, at 04:17 TRT (01:17 UTC), ...   \n",
       "70  The Turkish Government was criticized on socia...   \n",
       "..                                                ...   \n",
       "27                                             \\t\\t\\t   \n",
       "28                                             \\t\\t\\t   \n",
       "36                                             \\t\\t\\t   \n",
       "31                                             \\t\\t\\t   \n",
       "35                                             \\t\\t\\t   \n",
       "\n",
       "                                           embeddings  distances  \n",
       "2   [-0.00367865 -0.02011255 -0.01324833 ...  0.00...   0.087936  \n",
       "45  [-0.00564726 -0.02702904  0.00706243 ...  0.00...   0.102309  \n",
       "46  [ 0.01216849 -0.00288201 -0.00684733 ... -0.00...   0.116451  \n",
       "0   [-0.00786579 -0.01488738 -0.01354739 ... -0.00...   0.116957  \n",
       "70  [-5.34295512e-04 -8.55211547e-05 -6.40815916e-...   0.122179  \n",
       "..                                                ...        ...  \n",
       "27  [-0.01989811 -0.02768373 -0.02324662 ... -0.01...   0.296139  \n",
       "28  [-0.01989811 -0.02768373 -0.02324662 ... -0.01...   0.296139  \n",
       "36  [-0.01992117 -0.02773259 -0.02331025 ... -0.01...   0.296254  \n",
       "31  [-0.01992117 -0.02773259 -0.02331025 ... -0.01...   0.296254  \n",
       "35  [-0.01992117 -0.02773259 -0.02331025 ... -0.01...   0.296254  \n",
       "\n",
       "[101 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>distances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There was widespread damage in an area of abou...</td>\n",
       "      <td>[-0.00367865 -0.02011255 -0.01324833 ...  0.00...</td>\n",
       "      <td>0.087936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>The USGS Prompt Assessment of Global Earthquak...</td>\n",
       "      <td>[-0.00564726 -0.02702904  0.00706243 ...  0.00...</td>\n",
       "      <td>0.102309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>The United Nations Development Programme estim...</td>\n",
       "      <td>[ 0.01216849 -0.00288201 -0.00684733 ... -0.00...</td>\n",
       "      <td>0.116451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On 6 February 2023, at 04:17 TRT (01:17 UTC), ...</td>\n",
       "      <td>[-0.00786579 -0.01488738 -0.01354739 ... -0.00...</td>\n",
       "      <td>0.116957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>The Turkish Government was criticized on socia...</td>\n",
       "      <td>[-5.34295512e-04 -8.55211547e-05 -6.40815916e-...</td>\n",
       "      <td>0.122179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>\\t\\t\\t</td>\n",
       "      <td>[-0.01989811 -0.02768373 -0.02324662 ... -0.01...</td>\n",
       "      <td>0.296139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>\\t\\t\\t</td>\n",
       "      <td>[-0.01989811 -0.02768373 -0.02324662 ... -0.01...</td>\n",
       "      <td>0.296139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>\\t\\t\\t</td>\n",
       "      <td>[-0.01992117 -0.02773259 -0.02331025 ... -0.01...</td>\n",
       "      <td>0.296254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>\\t\\t\\t</td>\n",
       "      <td>[-0.01992117 -0.02773259 -0.02331025 ... -0.01...</td>\n",
       "      <td>0.296254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>\\t\\t\\t</td>\n",
       "      <td>[-0.01992117 -0.02773259 -0.02331025 ... -0.01...</td>\n",
       "      <td>0.296254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows Ã— 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "757505cb",
   "metadata": {},
   "source": [
    "## TODO 1: Build the Custom Text Prompt\n",
    "\n",
    "Run the cell below as-is:"
   ]
  },
  {
   "cell_type": "code",
   "id": "d2c16528",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-26T21:07:30.818256Z",
     "start_time": "2025-01-26T21:07:30.464649Z"
    }
   },
   "source": [
    "import tiktoken\n",
    "# Create a tokenizer that is designed to align with our embeddings\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "token_limit = 1000\n",
    "USER_QUESTION = \"\"\"What were the estimated damages of the 2023 \\\n",
    "Turkey-Syria earthquake?\"\"\""
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tiktoken'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtiktoken\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# Create a tokenizer that is designed to align with our embeddings\u001B[39;00m\n\u001B[1;32m      3\u001B[0m tokenizer \u001B[38;5;241m=\u001B[39m tiktoken\u001B[38;5;241m.\u001B[39mget_encoding(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcl100k_base\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'tiktoken'"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "e04c0ca1",
   "metadata": {},
   "source": [
    "Now your task is to compose the custom text prompt.\n",
    "\n",
    "The overall structure of the prompt should look like this:\n",
    "\n",
    "```\n",
    "Answer the question based on the context below, and if the\n",
    "question can't be answered based on the context, say \"I don't\n",
    "know\"\n",
    "\n",
    "Context:\n",
    "\n",
    "{context}\n",
    "\n",
    "---\n",
    "\n",
    "Question: {question}\n",
    "Answer:\n",
    "```\n",
    "\n",
    "In the place marked `context`, provide as much information from `df['text']` as possible without exceeding `token_limit`. In the place marked `question`, add `USER_QUESTION`.\n",
    "\n",
    "Your overall goal is to create a string called `prompt` that contains all of the relevant information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de013ac",
   "metadata": {},
   "source": [
    "If you're getting stuck, you can click to reveal the solution then copy and paste this into the cell below.\n",
    "\n",
    "---\n",
    "\n",
    "<details>\n",
    "    <summary style=\"cursor: pointer\"><strong>Solution (click to show/hide)</strong></summary>\n",
    "\n",
    "```python\n",
    "# Count the number of tokens in the prompt template and question\n",
    "prompt_template = \"\"\"\n",
    "Answer the question based on the context below, and if the \n",
    "question can't be answered based on the context, say \n",
    "\"I don't know\"\n",
    "\n",
    "Context: \n",
    "\n",
    "{}\n",
    "\n",
    "---\n",
    "\n",
    "Question: {}\n",
    "Answer:\"\"\"\n",
    "token_count = len(tokenizer.encode(prompt_template)) + \\\n",
    "                        len(tokenizer.encode(USER_QUESTION))\n",
    "\n",
    "# Create a list to store text for context\n",
    "context_list = []\n",
    "\n",
    "# Loop over rows of the sorted dataframe\n",
    "for text in df[\"text\"].values:\n",
    "    \n",
    "    # Append text to context_list if there is enough room\n",
    "    token_count += len(tokenizer.encode(text))\n",
    "    if token_count <= token_limit:\n",
    "        context_list.append(text)\n",
    "    else:\n",
    "        # Break once we're over the token limit\n",
    "        break\n",
    "\n",
    "# Use string formatting to complete the prompt\n",
    "prompt = prompt_template.format(\n",
    "    \"\\n\\n###\\n\\n\".join(context_list),\n",
    "    USER_QUESTION\n",
    ")\n",
    "print(prompt)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06acf260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of tokens in the prompt template and question\n",
    "prompt_template = \"\"\"\n",
    "Answer the question based on the context below, and if the \n",
    "question can't be answered based on the context, say \n",
    "\"I don't know\"\n",
    "\n",
    "Context: \n",
    "\n",
    "{}\n",
    "\n",
    "---\n",
    "\n",
    "Question: {}\n",
    "Answer:\"\"\"\n",
    "token_count = \n",
    "\n",
    "# Create a list to store text for context\n",
    "context_list = \n",
    "\n",
    "# Loop over rows of the sorted dataframe\n",
    "for text in df[\"text\"].values:\n",
    "    \n",
    "    # Append text to context_list if there is enough room\n",
    "    \n",
    "\n",
    "# Use string formatting to complete the prompt\n",
    "prompt = prompt_template.format(\n",
    "    \"\\n\\n###\\n\\n\".join(context_list),\n",
    "    USER_QUESTION\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a097f24d",
   "metadata": {},
   "source": [
    "## TODO 2: Send Custom Text Prompt to Completion Model\n",
    "\n",
    "Using the `prompt` string you created, query an OpenAI `Completion` model to get an answer. Specify a `max_tokens` of 150.\n",
    "\n",
    "If you're getting stuck, you can click to reveal the solution then copy and paste this into the cell below.\n",
    "\n",
    "---\n",
    "\n",
    "<details>\n",
    "    <summary style=\"cursor: pointer\"><strong>Solution (click to show/hide)</strong></summary>\n",
    "\n",
    "```python\n",
    "COMPLETION_MODEL_NAME = \"gpt-3.5-turbo-instruct\"\n",
    "response = openai.Completion.create(\n",
    "    model=COMPLETION_MODEL_NAME,\n",
    "    prompt=prompt,\n",
    "    max_tokens=150\n",
    ")\n",
    "answer = response[\"choices\"][0][\"text\"].strip()\n",
    "print(answer)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b35a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETION_MODEL_NAME = \"gpt-3.5-turbo-instruct\"\n",
    "response = \n",
    "answer = \n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70191209",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Congratulations ðŸŽ‰\n",
    "\n",
    "You have now completed the prompt engineering process using unsupervised ML to get a custom answer from an OpenAI model!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
