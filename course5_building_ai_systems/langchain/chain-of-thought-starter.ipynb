{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SOLUTION: https://youtu.be/RV8Zv9_3UHE\n",
    "\n",
    "Let's see if we can solve a simple math problem with gpt-3.5"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T21:57:05.717233Z",
     "start_time": "2025-02-03T21:57:05.709665Z"
    }
   },
   "source": [
    "# Add prereq code to set open API key\n",
    "\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] =\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://openai.vocareum.com/v1\""
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T21:59:54.811467Z",
     "start_time": "2025-02-03T21:59:49.632926Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "temperature = 0.0\n",
    "llm = OpenAI(model_name=model_name, temperature=temperature, max_tokens = 500)\n",
    "\n",
    "# Note: example taken from\n",
    "# https://browse.arxiv.org/pdf/2303.12712.pdf\n",
    "\n",
    "instruction = \"\"\"\n",
    "Andy harvests all the tomatoes from 18 plants that have 7 tomatoes each. If he dries half the\n",
    "tomatoes and turns a third of the remainder into marinara sauce, how many tomatoes are left?\n",
    "\"\"\"\n",
    "print(\"Original Answer: \")\n",
    "print(llm(instruction))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tumaaa/work/repos/udacity_nano_degree_generative_ai/.venv/lib/python3.10/site-packages/langchain/llms/openai.py:202: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/home/tumaaa/work/repos/udacity_nano_degree_generative_ai/.venv/lib/python3.10/site-packages/langchain/llms/openai.py:790: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Answer: \n",
      "First, we need to find out how many tomatoes Andy harvested in total:\n",
      "18 plants * 7 tomatoes per plant = 126 tomatoes\n",
      "\n",
      "Next, we need to find out how many tomatoes Andy dried:\n",
      "126 tomatoes / 2 = 63 dried tomatoes\n",
      "\n",
      "Now, we need to find out how many tomatoes Andy turned into marinara sauce:\n",
      "(126 tomatoes - 63 dried tomatoes) / 3 = 21 tomatoes turned into marinara sauce\n",
      "\n",
      "Finally, we need to find out how many tomatoes are left:\n",
      "126 tomatoes - 63 dried tomatoes - 21 tomatoes turned into marinara sauce = 42 tomatoes left\n",
      "\n",
      "Therefore, Andy is left with 42 tomatoes.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we run this, we see an incorrect answer:\n",
    "Original Answer: \n",
    "Andy harvests a total of 18 plants * 7 tomatoes/plant = <<18*7=126>>126 tomatoes.\n",
    "He dries half of the tomatoes, so he has 126 tomatoes / 2 = <<126/2=63>>63 tomatoes left.\n",
    "He turns a third of the remaining tomatoes into marinara sauce, so he has 63 tomatoes * 1/3 = <<63*1/3=21>>21 tomatoes left. Answer: \\boxed{21}.\n",
    "\n",
    "In reality, Andy will have 63 - 21 = 42 tomatoes left\n",
    "\n",
    "Let's see how we can fix this with Chain Of Thought Reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's setup a examples of how we want LLM to think about the problem"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T22:00:47.062807Z",
     "start_time": "2025-02-03T22:00:47.051292Z"
    }
   },
   "source": [
    "\n",
    "question1 = \"\"\"\n",
    "Karen harvests all the pears from 20 trees that have 10 pears each. She  throws a third of them away as they are rotten,\n",
    "and turns a quarter of the remaining ones into jam. How many are left?\n",
    "\"\"\"\n",
    "answer1 = \"\"\"\n",
    "    First, let's calculate how many pears Gloria harvests: it's 20 * 10 = 200. \n",
    "    Then, let's calculate how many are rotten: 200 * 1/3 = 66.\n",
    "    Thus, we know how many are left after she throws a third of them away: 200 - 66 = 134.\n",
    "    1/4 of the remaining ones are turned into jam, or 134 * 1/4 = 33. Therefore, Karen is left with 134 - 33, or 101 pears\n",
    "\"\"\"\n",
    "question2 = \"\"\"\n",
    "Sergei harvests all the strawberries from 50 plants that have 8 stawberries each. He freezes a quarter of them,\n",
    "and turns half of the remaining ones into jam. How many are left?\n",
    "\"\"\"\n",
    "answer2 = \"\"\"\n",
    "    First, let's calculate how many strawberries Sergei harvests: it's 50 * 8 = 400. \n",
    "    Then, let's calculate how many are frozen: 400 * 1/4 = 100.\n",
    "    Thus, we know how many are left after he freezes 100 of them: 400 - 100 = 300.\n",
    "    half of the remaining ones are turned into jam, or 300 * 1/2 = 150. Therefore, Sergei is left with 300 - 150, or 150 pears\n",
    "\"\"\""
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's setup an prompt template for one question/answer pair, and put our examples into an array"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T22:06:33.137759Z",
     "start_time": "2025-02-03T22:06:33.129297Z"
    }
   },
   "source": [
    "example_prompt = PromptTemplate(input_variables=[\"question\", \"answer\"], template=\"{question}\\n{answer}\")\n",
    "# TODO: setup an array of question / answer examples\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": question1,\n",
    "        \"answer\": answer1\n",
    "    },\n",
    "    {\n",
    "        \"question\": question2,\n",
    "        \"answer\": answer2\n",
    "    },\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's setup the FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T22:06:34.664892Z",
     "start_time": "2025-02-03T22:06:34.659125Z"
    }
   },
   "source": [
    "# TODO: setup chain of thought prompt template based on few shot prompt template\n",
    "cot_prompt = FewShotPromptTemplate(examples=examples, example_prompt=example_prompt, suffix = \"Use these question-answers to give correct answer to the problem below: {input}\", input_variables=[\"input\"])"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's use the same instruction as before and see if we get a different answer"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-03T22:06:42.514899Z",
     "start_time": "2025-02-03T22:06:39.744764Z"
    }
   },
   "source": [
    "\n",
    "cot_text = cot_prompt.format(input=instruction)\n",
    "print(\"=== Chain of Thought Prompt ===\")\n",
    "print(cot_text)\n",
    "print(\"=== Chain of Thought Answer ===\")\n",
    "print(llm(cot_text))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Chain of Thought Prompt ===\n",
      "\n",
      "Karen harvests all the pears from 20 trees that have 10 pears each. She  throws a third of them away as they are rotten,\n",
      "and turns a quarter of the remaining ones into jam. How many are left?\n",
      "\n",
      "\n",
      "    First, let's calculate how many pears Gloria harvests: it's 20 * 10 = 200. \n",
      "    Then, let's calculate how many are rotten: 200 * 1/3 = 66.\n",
      "    Thus, we know how many are left after she throws a third of them away: 200 - 66 = 134.\n",
      "    1/4 of the remaining ones are turned into jam, or 134 * 1/4 = 33. Therefore, Karen is left with 134 - 33, or 101 pears\n",
      "\n",
      "\n",
      "\n",
      "Sergei harvests all the strawberries from 50 plants that have 8 stawberries each. He freezes a quarter of them,\n",
      "and turns half of the remaining ones into jam. How many are left?\n",
      "\n",
      "\n",
      "    First, let's calculate how many strawberries Sergei harvests: it's 50 * 8 = 400. \n",
      "    Then, let's calculate how many are frozen: 400 * 1/4 = 100.\n",
      "    Thus, we know how many are left after he freezes 100 of them: 400 - 100 = 300.\n",
      "    half of the remaining ones are turned into jam, or 300 * 1/2 = 150. Therefore, Sergei is left with 300 - 150, or 150 pears\n",
      "\n",
      "\n",
      "Use these question-answers to give correct answer to the problem below: \n",
      "Andy harvests all the tomatoes from 18 plants that have 7 tomatoes each. If he dries half the\n",
      "tomatoes and turns a third of the remainder into marinara sauce, how many tomatoes are left?\n",
      "\n",
      "=== Chain of Thought Answer ===\n",
      "Using the same logic as above:\n",
      "\n",
      "Andy harvests 18 * 7 = 126 tomatoes.\n",
      "He dries half of them, which is 126 * 1/2 = 63 tomatoes.\n",
      "After drying, he is left with 126 - 63 = 63 tomatoes.\n",
      "He turns a third of the remaining ones into marinara sauce, which is 63 * 1/3 = 21 tomatoes.\n",
      "Therefore, Andy is left with 63 - 21 = 42 tomatoes.\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
